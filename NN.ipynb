{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "from collections import Counter\n",
    "from numpy import inf\n",
    "iris = load_iris()\n",
    "X_ion = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ion = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\",\n",
    "    usecols=np.arange(34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ion = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\",\n",
    "    usecols=34, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting iris dataset into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_iris_train, X_iris_test, y_iris_train, y_iris_test = train_test_split(iris['data'],\n",
    "iris['target'], random_state=301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting ionosphere dataset into training and test sets\n",
    "X_ion_train, X_ion_test, y_ion_train, y_ion_test = train_test_split(X_ion,\n",
    "y_ion, random_state=301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideanDistance(x_test_dist, x_train_dist):                          #Computes the Euclidean distance using numpy array\n",
    "    \"\"\"\n",
    "    This functions takes two parameters and calculates the Euclidean Distance between them\n",
    "    \"\"\"\n",
    "    sums = np.sum((x_test_dist-x_train_dist)**2, axis=1)                   #axis 1 means row wise summation\n",
    "    return np.sqrt(sums)                                                   #square root of the sum of squares to calculate the distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function euclideanDistance in module __main__:\n",
      "\n",
      "euclideanDistance(x_test_dist, x_train_dist)\n",
      "    This functions takes two parameters and calculates the Euclidean Distance between them\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(euclideanDistance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNeighbourNeighboursClassifier(X_train,X_test,y_train,k):               #implementation of k nearest neighbour for all k\n",
    "    \"\"\"\n",
    "    This function takes the number of neighbours for the K nearest neighbours algorithm and calculates the nearest neighbour bases on it.\n",
    "    \"\"\"\n",
    "    y_predicted_label_set = np.array([]).astype(int)                        #predicted label set to be returned for test set\n",
    "    for x_test_individual in X_test:                                        #looping through each row/sample of test data set\n",
    "        euc_distance = euclideanDistance(x_test_individual,X_train)         #calling the euclidean distance methos we declared\n",
    "        shortest_distance = np.argpartition(euc_distance,k)[:k]             #avoids shorting the whole array\n",
    "        possible_y_label = [y_train[index] for index in shortest_distance]  #set of y_labels\n",
    "        vote_for_labels = Counter(possible_y_label)                         #using counter collections\n",
    "        value, count = vote_for_labels.most_common()[0]                     #find most occuring label\n",
    "        y_predicted_label_set = np.append(y_predicted_label_set, value)     #add to the predicted label set\n",
    "    return y_predicted_label_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function kNeighbourNeighboursClassifier in module __main__:\n",
      "\n",
      "kNeighbourNeighboursClassifier(X_train, X_test, y_train, k)\n",
      "    This function takes the number of neighbours for the K nearest neighbours algorithm and calculates the nearest neighbour bases on it.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(kNeighbourNeighboursClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of Test set label:\n",
      " [2 0 1 2 0 2 2 0 0 1 2 1 0 1 0 0 0 2 2 1 0 1 0 0 0 2 0 2 1 2 0 1 1 1 1 0 1\n",
      " 2]\n",
      "Number of errors made:  1\n",
      "Test Error rate:  0.02631578947368421\n"
     ]
    }
   ],
   "source": [
    "#prediction for 1NN for iris dataset\n",
    "y_pred = kNeighbourNeighboursClassifier(X_iris_train,X_iris_test,y_iris_train,1) \n",
    "print(\"Prediction of Test set label:\\n\", y_pred)\n",
    "print(\"Number of errors made: \", sum(y_pred != y_iris_test))\n",
    "print(\"Test Error rate: \",sum(y_pred != y_iris_test)/len(y_iris_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of Test set label:\n",
      " [2 0 1 2 0 2 2 0 0 1 2 1 0 1 0 0 0 2 2 1 0 1 0 0 0 2 0 2 1 2 0 1 1 1 1 0 1\n",
      " 2]\n",
      "Number of errors made :  1\n",
      "Test Error rate:  0.02631578947368421\n"
     ]
    }
   ],
   "source": [
    "#prediction for 3NN for iris dataset\n",
    "y_pred = kNeighbourNeighboursClassifier(X_iris_train,X_iris_test,y_iris_train,3) \n",
    "print(\"Prediction of Test set label:\\n\", y_pred)\n",
    "print(\"Number of errors made : \", sum(y_pred != y_iris_test))\n",
    "print(\"Test Error rate: \",sum(y_pred != y_iris_test)/len(y_iris_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of Test set label:\n",
      " [ 1  1  1 -1  1  1  1  1  1  1  1 -1  1  1 -1  1  1  1  1  1  1  1 -1 -1\n",
      " -1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1 -1 -1\n",
      " -1  1  1 -1  1  1  1  1 -1  1 -1 -1  1  1  1  1  1  1  1  1  1 -1 -1  1\n",
      "  1  1 -1 -1 -1  1  1  1  1 -1  1 -1  1  1  1 -1]\n",
      "Number of errors made :  8\n",
      "Test Error rate:  0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "#prediction for 1NN for ionosphere dataset\n",
    "y_pred = kNeighbourNeighboursClassifier(X_ion_train,X_ion_test,y_ion_train,1) \n",
    "print(\"Prediction of Test set label:\\n\", y_pred)\n",
    "print(\"Number of errors made : \", sum(y_pred != y_ion_test))\n",
    "print(\"Test Error rate: \",sum(y_pred != y_ion_test)/len(y_ion_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of Test set label:\n",
      " [ 1  1  1 -1  1  1  1  1  1  1  1 -1  1  1 -1  1  1  1  1  1  1  1 -1 -1\n",
      " -1 -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 -1  1  1  1  1  1  1 -1\n",
      " -1  1  1  1  1  1  1 -1 -1  1 -1 -1  1  1  1  1  1  1  1  1  1 -1 -1  1\n",
      "  1  1 -1  1 -1 -1  1 -1  1 -1  1 -1  1  1  1 -1]\n",
      "Number of errors made :  10\n",
      "Test Error rate:  0.11363636363636363\n"
     ]
    }
   ],
   "source": [
    "#prediction for 3NN for ionosphere dataset\n",
    "y_pred = kNeighbourNeighboursClassifier(X_ion_train,X_ion_test,y_ion_train,3) \n",
    "print(\"Prediction of Test set label:\\n\", y_pred)\n",
    "print(\"Number of errors made : \", sum(y_pred != y_ion_test))\n",
    "print(\"Test Error rate: \",sum(y_pred != y_ion_test)/len(y_ion_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of Test set label:\n",
      " [2 0 1 2 0 2 2 0 0 1 2 1 0 1 0 0 0 2 2 1 0 1 0 0 0 2 0 2 1 2 0 1 1 1 1 0 1\n",
      " 2]\n",
      "Number of errors made:  1\n",
      "Test Error rate:  0.02631578947368421\n"
     ]
    }
   ],
   "source": [
    "#prediction for 5NN for iris dataset\n",
    "y_pred = kNeighbourNeighboursClassifier(X_iris_train,X_iris_test,y_iris_train,5) \n",
    "print(\"Prediction of Test set label:\\n\", y_pred)\n",
    "print(\"Number of errors made: \", sum(y_pred != y_iris_test))\n",
    "print(\"Test Error rate: \",sum(y_pred != y_iris_test)/len(y_iris_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of Test set label:\n",
      " [2 0 1 2 0 2 2 0 0 1 2 1 0 1 0 0 0 2 2 1 0 1 0 0 0 2 0 2 1 2 0 1 1 1 1 0 1\n",
      " 2]\n",
      "Number of errors made:  1\n",
      "Test Error rate:  0.02631578947368421\n"
     ]
    }
   ],
   "source": [
    "#prediction for 5NN for iris dataset\n",
    "y_pred = kNeighbourNeighboursClassifier(X_iris_train,X_iris_test,y_iris_train,5) \n",
    "print(\"Prediction of Test set label:\\n\", y_pred)\n",
    "print(\"Number of errors made: \", sum(y_pred != y_iris_test))\n",
    "print(\"Test Error rate: \",sum(y_pred != y_iris_test)/len(y_iris_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conformalPredictor(X_train,X_test,y_train, label_domain):\n",
    "    \"\"\"\n",
    "    This function computes the p value - conformal prediction for each of the test sample data for all the labels\n",
    "    \"\"\"\n",
    "    p_value_array  = None\n",
    "    for x_test_individual in X_test:                                                                  #looping through rach test data\n",
    "        p_value_array_for_all_label = np.zeros(len(label_domain))\n",
    "        for index_no,n in enumerate(label_domain):                                                    #looping through each distinct label\n",
    "            X_train_with_test = np.vstack((X_train,x_test_individual))                                #adding test data to training data and creating new sample \n",
    "            y_train_with_test = np.append(y_train,n)\n",
    "            distances = np.zeros(len(X_train_with_test))  \n",
    "            #count = 0\n",
    "            for index, a in enumerate(X_train_with_test):  \n",
    "                indexes_with_same_label =(y_train_with_test == y_train_with_test[index]).nonzero() [0]\n",
    "                indexes_with_same_label = indexes_with_same_label[indexes_with_same_label != index]\n",
    "                distances_same = np.linalg.norm(X_train_with_test[indexes_with_same_label]-a,axis=1)   #calcutating same distance\n",
    "                min_distance_same = np.min(distances_same)                                             #getting minimum\n",
    "                indexes_with_diff_label =(y_train_with_test != y_train_with_test[index]).nonzero() [0] \n",
    "                #indexes_with_diff_label = indexes_with_diff_label[indexes_with_diff_label != index]\n",
    "                distances_diff = np.linalg.norm(X_train_with_test[indexes_with_diff_label]-a,axis=1)  #calcutation different distance\n",
    "                min_distance_diff = np.min(distances_diff)                                            #getting minimum\n",
    "                if min_distance_same == 0 :                                                           #handling 0/0 cases - start\n",
    "                    if min_distance_diff != 0:\n",
    "                        distances[index] = inf\n",
    "                    else:\n",
    "                        distances[index] = 0    \n",
    "                else:\n",
    "                    distances[index] = min_distance_diff/min_distance_same                            #handling 0/0 cases - end\n",
    "            rank = len(distances) - sum(distances>distances[-1])                                      #calculating rank for one label\n",
    "            p_value = rank/len(distances)                                                             #getting p value for one label\n",
    "            p_value_array_for_all_label[index_no] = p_value                                           #merging p values for all labels for one dataset\n",
    "        if p_value_array is None:\n",
    "            p_value_array = p_value_array_for_all_label\n",
    "        else:\n",
    "            p_value_array = np.vstack((p_value_array,p_value_array_for_all_label))\n",
    "    return(p_value_array)                                                                             #returning p values for all test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P values for iris dataset: \n",
      " [[0.00884956 0.00884956 0.55752212]\n",
      " [0.88495575 0.00884956 0.00884956]\n",
      " [0.00884956 0.51327434 0.00884956]\n",
      " [0.00884956 0.03539823 0.07079646]\n",
      " [0.88495575 0.00884956 0.00884956]\n",
      " [0.00884956 0.01769912 0.15044248]\n",
      " [0.00884956 0.00884956 0.66371681]\n",
      " [0.69026549 0.00884956 0.00884956]\n",
      " [0.92920354 0.00884956 0.00884956]\n",
      " [0.00884956 0.30973451 0.00884956]\n",
      " [0.00884956 0.00884956 0.52212389]\n",
      " [0.00884956 0.07079646 0.03539823]\n",
      " [0.7699115  0.00884956 0.00884956]\n",
      " [0.00884956 0.77876106 0.00884956]\n",
      " [0.96460177 0.00884956 0.00884956]\n",
      " [0.77876106 0.00884956 0.00884956]\n",
      " [0.66371681 0.00884956 0.00884956]\n",
      " [0.00884956 0.00884956 0.51327434]\n",
      " [0.00884956 0.04424779 0.07079646]\n",
      " [0.00884956 0.3539823  0.00884956]\n",
      " [0.77876106 0.00884956 0.00884956]\n",
      " [0.00884956 0.46017699 0.00884956]\n",
      " [0.85840708 0.00884956 0.00884956]\n",
      " [0.79646018 0.00884956 0.00884956]\n",
      " [0.67256637 0.00884956 0.00884956]\n",
      " [0.00884956 0.00884956 0.52212389]\n",
      " [0.95575221 0.00884956 0.00884956]\n",
      " [0.00884956 0.00884956 0.7699115 ]\n",
      " [0.00884956 0.30088496 0.00884956]\n",
      " [0.00884956 0.00884956 0.3539823 ]\n",
      " [0.61061947 0.00884956 0.00884956]\n",
      " [0.00884956 0.34513274 0.00884956]\n",
      " [0.00884956 0.49557522 0.00884956]\n",
      " [0.00884956 0.47787611 0.00884956]\n",
      " [0.00884956 0.30973451 0.00884956]\n",
      " [0.67256637 0.00884956 0.00884956]\n",
      " [0.00884956 0.28318584 0.00884956]\n",
      " [0.00884956 0.00884956 0.3539823 ]]\n",
      "\n",
      "Accuracy of the model for iris dataset:  0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "#calculating p value for iris dataset\n",
    "y_iris_p_values = conformalPredictor(X_iris_train,X_iris_test,y_iris_train, [ i for i in range(0, len(iris.target_names))])\n",
    "y_hat = np.argmax(y_iris_p_values,axis=1)\n",
    "print(\"P values for iris dataset: \\n\",y_iris_p_values)\n",
    "print(\"\\nAccuracy of the model for iris dataset: \",np.mean(y_hat==y_iris_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P values for ionosphere dataset: \n",
      " [[0.00378788 0.86742424]\n",
      " [0.00378788 0.90151515]\n",
      " [0.00378788 0.95833333]\n",
      " [0.28787879 0.08712121]\n",
      " [0.00378788 0.79545455]\n",
      " [0.00757576 0.48863636]\n",
      " [0.00378788 0.76136364]\n",
      " [0.08712121 0.27272727]\n",
      " [0.00378788 0.74621212]\n",
      " [0.00378788 0.74242424]\n",
      " [0.00378788 0.76893939]\n",
      " [0.33712121 0.05681818]\n",
      " [0.03409091 0.39393939]\n",
      " [0.00757576 0.48106061]\n",
      " [0.41287879 0.03409091]\n",
      " [0.00378788 0.95454545]\n",
      " [0.00757576 0.48106061]\n",
      " [0.01136364 0.48863636]\n",
      " [0.00378788 0.93560606]\n",
      " [0.13636364 0.17424242]\n",
      " [0.00378788 0.75378788]\n",
      " [0.00378788 0.66666667]\n",
      " [0.33333333 0.05681818]\n",
      " [0.16666667 0.14772727]\n",
      " [0.1969697  0.12878788]\n",
      " [0.29166667 0.08712121]\n",
      " [0.00757576 0.625     ]\n",
      " [0.00757576 0.52651515]\n",
      " [0.00378788 0.76136364]\n",
      " [0.00378788 0.68939394]\n",
      " [0.00378788 0.94318182]\n",
      " [0.00757576 0.62121212]\n",
      " [0.02651515 0.43181818]\n",
      " [0.00378788 0.88257576]\n",
      " [0.00757576 0.59469697]\n",
      " [0.00757576 0.63636364]\n",
      " [0.00378788 0.84090909]\n",
      " [0.00378788 0.73484848]\n",
      " [0.00378788 0.84469697]\n",
      " [0.00378788 0.89393939]\n",
      " [0.3030303  0.0719697 ]\n",
      " [0.00378788 0.76893939]\n",
      " [0.01136364 0.47727273]\n",
      " [0.06818182 0.30681818]\n",
      " [0.00757576 0.62878788]\n",
      " [0.02651515 0.45075758]\n",
      " [0.16287879 0.14772727]\n",
      " [0.29545455 0.07954545]\n",
      " [0.29924242 0.07954545]\n",
      " [0.00378788 0.97727273]\n",
      " [0.00378788 0.82954545]\n",
      " [0.17424242 0.13636364]\n",
      " [0.00378788 0.9280303 ]\n",
      " [0.00378788 0.81818182]\n",
      " [0.00378788 0.70454545]\n",
      " [0.15151515 0.15909091]\n",
      " [0.66666667 0.00378788]\n",
      " [0.00378788 0.90530303]\n",
      " [0.42424242 0.03030303]\n",
      " [0.28409091 0.08712121]\n",
      " [0.00378788 0.66666667]\n",
      " [0.00757576 0.59090909]\n",
      " [0.00378788 0.81818182]\n",
      " [0.00757576 0.63257576]\n",
      " [0.00757576 0.62121212]\n",
      " [0.00378788 0.71590909]\n",
      " [0.00378788 0.79924242]\n",
      " [0.00378788 0.69318182]\n",
      " [0.14015152 0.17045455]\n",
      " [0.25       0.09469697]\n",
      " [0.37121212 0.04924242]\n",
      " [0.00378788 0.86363636]\n",
      " [0.00378788 0.86363636]\n",
      " [0.00378788 0.71212121]\n",
      " [0.1969697  0.13636364]\n",
      " [0.22348485 0.10227273]\n",
      " [0.33712121 0.0530303 ]\n",
      " [0.14393939 0.17045455]\n",
      " [0.00378788 0.69318182]\n",
      " [0.13257576 0.18181818]\n",
      " [0.00378788 0.81818182]\n",
      " [0.28409091 0.08712121]\n",
      " [0.00378788 0.98106061]\n",
      " [0.52651515 0.00378788]\n",
      " [0.04166667 0.36363636]\n",
      " [0.00378788 0.66287879]\n",
      " [0.00378788 0.79166667]\n",
      " [1.         0.00757576]]\n",
      "\n",
      "Accuracy of the model for ionosphere dataset:  0.6590909090909091\n"
     ]
    }
   ],
   "source": [
    "#calculating p values for ionosphere dataset\n",
    "y_ion_p_values = conformalPredictor(X_ion_train,X_ion_test,y_ion_train, [-1, 1])\n",
    "print(\"P values for ionosphere dataset: \\n\",y_ion_p_values)\n",
    "y_hat = np.argmax(y_ion_p_values,axis=1)\n",
    "print(\"\\nAccuracy of the model for ionosphere dataset: \",np.mean(y_hat==y_ion_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate average false p value for the given datset\n",
    "def averageFalseP(y_test,y_p_values):\n",
    "    avg_false_p_value = 0\n",
    "    total_sum_rowwise = 0\n",
    "    num_rows, num_cols = y_p_values.shape\n",
    "    for index_label,n in enumerate(y_test):                           #looping over each test data label\n",
    "        for index_p_value,m in enumerate(y_p_values):                 #looping over each row of p value data array\n",
    "            if index_label == index_p_value:                          #comparing indexed for y_\n",
    "                sum = 0\n",
    "                for index, o in enumerate(y_p_values[index_p_value]): #looping over each row value for p value array\n",
    "                    if n != index:                                    #eliminating true label\n",
    "                        sum = sum+o\n",
    "                avg_rowwise = sum/(num_cols-1)\n",
    "                total_sum_rowwise = total_sum_rowwise + avg_rowwise   #getting total false p values sum\n",
    "    avg_false_p_value = total_sum_rowwise/(y_p_values.size-num_rows)\n",
    "    return(avg_false_p_value)                                         #returning average false p value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average false p value for iris dataset:  0.005298090358639967\n",
      "Accuracy:  0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "#calculating average false p value for iris dataset\n",
    "average_false_p_vale_iris = averageFalseP(y_iris_test,y_iris_p_values)\n",
    "print(\"Average false p value for iris dataset: \",average_false_p_vale_iris)\n",
    "y_hat = np.argmax(y_iris_p_values,axis=1)\n",
    "print(\"Accuracy: \",np.mean(y_hat==y_iris_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average false p value for ionosphere dataset:  0.14445592286501385\n",
      "Accuracy:  0.6590909090909091\n"
     ]
    }
   ],
   "source": [
    "#calculating average false p value for ionosphere dataset\n",
    "average_false_p_vale_ion = averageFalseP(y_ion_test,y_ion_p_values)\n",
    "print(\"Average false p value for ionosphere dataset: \",average_false_p_vale_ion)\n",
    "y_hat = np.argmax(y_ion_p_values,axis=1)\n",
    "print(\"Accuracy: \",np.mean(y_hat==y_ion_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction of Test set label:\n",
      " [2 0 1 2 0 2 2 0 0 1 2 1 0 1 0 0 0 2 2 1 0 1 0 0 0 2 0 2 1 2 0 1 1 1 1 0 1\n",
      " 2]\n",
      "Number of errors made:  1\n",
      "Test Error rate:  0.02631578947368421\n"
     ]
    }
   ],
   "source": [
    "#prediction for 5NN for iris dataset\n",
    "y_pred = kNeighbourNeighboursClassifier(X_iris_train,X_iris_test,y_iris_train,5) \n",
    "print(\"Prediction of Test set label:\\n\", y_pred)\n",
    "print(\"Number of errors made: \", sum(y_pred != y_iris_test))\n",
    "print(\"Test Error rate: \",sum(y_pred != y_iris_test)/len(y_iris_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
